import { EventEmitter } from 'eventemitter3';
import { v4 as uuidv4 } from 'uuid';
import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';
import Anthropic from '@anthropic-ai/sdk';
import axios from 'axios';
import { logger } from '../../shared/src/utils/logger.js';
import {
  MultiModelRequest,
  ModelResponse,
  AIProvider,
  ModelCapability,
  ModelProviderError
} from '../types/index.js';

/**
 * Coordinates multiple AI model providers for enhanced responses
 * Inspired by Claude Task Master patterns for multi-model abstraction
 */
export class ModelCoordinator extends EventEmitter {
  private providers: Map<AIProvider, ProviderClient>;
  private capabilityMatrix: Map<AIProvider, ModelCapability[]>;
  private providerHealth: Map<AIProvider, ProviderHealthStatus>;

  constructor() {
    super();
    this.providers = new Map();
    this.capabilityMatrix = new Map();
    this.providerHealth = new Map();
    
    this.initializeProviders();
    this.initializeCapabilityMatrix();
  }

  /**
   * Initialize available AI providers
   */
  private initializeProviders(): void {
    // Claude provider (primary)
    this.providers.set('claude', new ClaudeProvider());
    
    // Mock providers for other models (would be implemented with actual APIs)
    this.providers.set('openai-gpt4', new OpenAIProvider('gpt-4'));
    this.providers.set('openai-gpt3.5', new OpenAIProvider('gpt-3.5-turbo'));
    this.providers.set('google-gemini', new GeminiProvider());
    
    // Initialize health status
    for (const provider of this.providers.keys()) {
      this.providerHealth.set(provider, {
        isHealthy: true,
        lastCheck: new Date(),
        responseTime: 0,
        errorRate: 0
      });
    }
    
    logger.info('Model providers initialized', {
      providerCount: this.providers.size
    });
  }

  /**
   * Initialize capability matrix for providers
   */
  private initializeCapabilityMatrix(): void {\n    this.capabilityMatrix.set('claude', [\n      'text-generation',\n      'code-analysis', \n      'reasoning',\n      'creative-writing',\n      'summarization',\n      'qa-answering'\n    ]);\n    \n    this.capabilityMatrix.set('openai-gpt4', [\n      'text-generation',\n      'code-analysis',\n      'reasoning', \n      'creative-writing',\n      'summarization'\n    ]);\n    \n    this.capabilityMatrix.set('openai-gpt3.5', [\n      'text-generation',\n      'summarization',\n      'qa-answering'\n    ]);\n    \n    this.capabilityMatrix.set('google-gemini', [\n      'text-generation',\n      'reasoning',\n      'translation',\n      'summarization'\n    ]);\n  }\n\n  /**\n   * Execute multi-model request\n   */\n  async executeRequest(request: MultiModelRequest): Promise<ModelResponse[]> {\n    try {\n      // Select optimal providers\n      const selectedProviders = await this.selectProviders(request);\n      \n      logger.info('Executing request with providers', {\n        requestId: request.id,\n        providers: selectedProviders,\n        strategy: request.fallbackStrategy\n      });\n      \n      // Execute based on fallback strategy\n      switch (request.fallbackStrategy) {\n        case 'parallel':\n          return await this.executeParallel(request, selectedProviders);\n        case 'sequential':\n          return await this.executeSequential(request, selectedProviders);\n        case 'consensus':\n          return await this.executeConsensus(request, selectedProviders);\n        default:\n          throw new Error(`Unknown fallback strategy: ${request.fallbackStrategy}`);\n      }\n      \n    } catch (error) {\n      logger.error('Multi-model request execution failed', {\n        requestId: request.id,\n        error: error instanceof Error ? error.message : 'Unknown error'\n      });\n      throw error;\n    }\n  }\n\n  /**\n   * Select optimal providers for request\n   */\n  private async selectProviders(request: MultiModelRequest): Promise<AIProvider[]> {\n    let candidates: AIProvider[] = [];\n    \n    // Start with preferred providers if specified\n    if (request.preferredProviders && request.preferredProviders.length > 0) {\n      candidates = request.preferredProviders.filter(provider => \n        this.providers.has(provider) && this.isProviderHealthy(provider)\n      );\n    }\n    \n    // If no valid preferred providers, find by capabilities\n    if (candidates.length === 0) {\n      candidates = this.findProvidersByCapabilities(request.requiredCapabilities);\n    }\n    \n    // Filter by health and limit count\n    const healthyCandidates = candidates\n      .filter(provider => this.isProviderHealthy(provider))\n      .slice(0, request.maxProviders);\n    \n    if (healthyCandidates.length === 0) {\n      throw new ModelProviderError(\n        'No healthy providers available for request',\n        'claude', // fallback to claude\n        { requiredCapabilities: request.requiredCapabilities }\n      );\n    }\n    \n    return healthyCandidates;\n  }\n\n  /**\n   * Find providers by required capabilities\n   */\n  private findProvidersByCapabilities(capabilities: ModelCapability[]): AIProvider[] {\n    const candidates: AIProvider[] = [];\n    \n    for (const [provider, providerCapabilities] of this.capabilityMatrix.entries()) {\n      const hasAllCapabilities = capabilities.every(cap => \n        providerCapabilities.includes(cap)\n      );\n      \n      if (hasAllCapabilities) {\n        candidates.push(provider);\n      }\n    }\n    \n    // Sort by capability count (more capable providers first)\n    return candidates.sort((a, b) => {\n      const aCaps = this.capabilityMatrix.get(a)?.length || 0;\n      const bCaps = this.capabilityMatrix.get(b)?.length || 0;\n      return bCaps - aCaps;\n    });\n  }\n\n  /**\n   * Execute requests in parallel\n   */\n  private async executeParallel(request: MultiModelRequest, providers: AIProvider[]): Promise<ModelResponse[]> {\n    const promises = providers.map(provider => \n      this.executeWithProvider(request, provider)\n    );\n    \n    try {\n      const responses = await Promise.allSettled(promises);\n      \n      return responses\n        .filter((result): result is PromiseFulfilledResult<ModelResponse> => \n          result.status === 'fulfilled'\n        )\n        .map(result => result.value);\n        \n    } catch (error) {\n      logger.error('Parallel execution failed', {\n        requestId: request.id,\n        providers,\n        error: error instanceof Error ? error.message : 'Unknown error'\n      });\n      throw error;\n    }\n  }\n\n  /**\n   * Execute requests sequentially with fallback\n   */\n  private async executeSequential(request: MultiModelRequest, providers: AIProvider[]): Promise<ModelResponse[]> {\n    const responses: ModelResponse[] = [];\n    let lastError: Error | null = null;\n    \n    for (const provider of providers) {\n      try {\n        const response = await this.executeWithProvider(request, provider);\n        responses.push(response);\n        \n        // If we get a high-confidence response, we can stop\n        if (response.confidence > 0.8) {\n          break;\n        }\n        \n      } catch (error) {\n        lastError = error instanceof Error ? error : new Error('Unknown error');\n        logger.warn('Provider failed, trying next', {\n          provider,\n          error: lastError.message\n        });\n        \n        // Mark provider as unhealthy temporarily\n        this.updateProviderHealth(provider, false);\n        continue;\n      }\n    }\n    \n    if (responses.length === 0 && lastError) {\n      throw lastError;\n    }\n    \n    return responses;\n  }\n\n  /**\n   * Execute with consensus approach\n   */\n  private async executeConsensus(request: MultiModelRequest, providers: AIProvider[]): Promise<ModelResponse[]> {\n    // Execute in parallel\n    const responses = await this.executeParallel(request, providers);\n    \n    if (responses.length < 2) {\n      return responses;\n    }\n    \n    // Simple consensus: return responses with above-average confidence\n    const avgConfidence = responses.reduce((sum, r) => sum + r.confidence, 0) / responses.length;\n    \n    return responses.filter(response => response.confidence >= avgConfidence);\n  }\n\n  /**\n   * Execute request with specific provider\n   */\n  private async executeWithProvider(request: MultiModelRequest, provider: AIProvider): Promise<ModelResponse> {\n    const startTime = Date.now();\n    \n    try {\n      const providerClient = this.providers.get(provider);\n      if (!providerClient) {\n        throw new ModelProviderError(`Provider not found: ${provider}`, provider);\n      }\n      \n      // Create prompt for the task\n      const prompt = this.createPromptForTask(request);\n      \n      // Execute with provider\n      const response = await providerClient.generateResponse(prompt, {\n        timeout: request.timeout,\n        maxTokens: 4000\n      });\n      \n      const executionTime = Date.now() - startTime;\n      \n      // Update provider health\n      this.updateProviderHealth(provider, true, executionTime);\n      \n      const modelResponse: ModelResponse = {\n        provider,\n        requestId: request.id,\n        taskId: request.task.id,\n        response: response.text,\n        confidence: response.confidence || 0.7,\n        tokenUsage: response.tokenUsage || 0,\n        executionTime,\n        metadata: response.metadata || {},\n        timestamp: new Date()\n      };\n      \n      // Emit success event\n      this.emit('response-received', modelResponse);\n      \n      return modelResponse;\n      \n    } catch (error) {\n      const executionTime = Date.now() - startTime;\n      \n      // Update provider health\n      this.updateProviderHealth(provider, false, executionTime);\n      \n      const providerError = new ModelProviderError(\n        `Provider execution failed: ${error instanceof Error ? error.message : 'Unknown error'}`,\n        provider,\n        { requestId: request.id, executionTime }\n      );\n      \n      // Emit error event\n      this.emit('provider-error', providerError);\n      \n      throw providerError;\n    }\n  }\n\n  /**\n   * Create prompt for task\n   */\n  private createPromptForTask(request: MultiModelRequest): string {\n    const task = request.task;\n    \n    let prompt = `Task: ${task.title}\n`;\n    \n    if (task.description) {\n      prompt += `Description: ${task.description}\n`;\n    }\n    \n    if (task.tags && task.tags.length > 0) {\n      prompt += `Tags: ${task.tags.join(', ')}\n`;\n    }\n    \n    prompt += `Priority: ${task.priority}\n`;\n    prompt += `Complexity: ${task.complexity}\n`;\n    \n    if (request.requiredCapabilities.length > 0) {\n      prompt += `Required capabilities: ${request.requiredCapabilities.join(', ')}\n`;\n    }\n    \n    prompt += `\nPlease provide a comprehensive response for this task.`;\n    \n    return prompt;\n  }\n\n  /**\n   * Check if provider is healthy\n   */\n  private isProviderHealthy(provider: AIProvider): boolean {\n    const health = this.providerHealth.get(provider);\n    return health?.isHealthy ?? false;\n  }\n\n  /**\n   * Update provider health status\n   */\n  private updateProviderHealth(provider: AIProvider, success: boolean, responseTime?: number): void {\n    const health = this.providerHealth.get(provider);\n    if (!health) return;\n    \n    health.lastCheck = new Date();\n    \n    if (responseTime !== undefined) {\n      health.responseTime = (health.responseTime + responseTime) / 2; // Moving average\n    }\n    \n    if (success) {\n      health.isHealthy = true;\n      health.errorRate = Math.max(0, health.errorRate - 0.1);\n    } else {\n      health.errorRate = Math.min(1, health.errorRate + 0.2);\n      health.isHealthy = health.errorRate < 0.5;\n    }\n  }\n\n  /**\n   * Get provider health status\n   */\n  getProviderHealth(): Map<AIProvider, ProviderHealthStatus> {\n    return new Map(this.providerHealth);\n  }\n\n  /**\n   * Cleanup resources\n   */\n  async cleanup(): Promise<void> {\n    try {\n      // Cleanup provider clients\n      for (const [provider, client] of this.providers.entries()) {\n        await client.cleanup?.();\n      }\n      \n      this.providers.clear();\n      this.capabilityMatrix.clear();\n      this.providerHealth.clear();\n      \n      logger.info('ModelCoordinator cleanup completed');\n      \n    } catch (error) {\n      logger.error('Error during ModelCoordinator cleanup', {\n        error: error instanceof Error ? error.message : 'Unknown error'\n      });\n      throw error;\n    }\n  }\n}\n\n// ==================== PROVIDER INTERFACES ====================\n\ninterface ProviderHealthStatus {\n  isHealthy: boolean;\n  lastCheck: Date;\n  responseTime: number;\n  errorRate: number;\n}\n\ninterface ProviderResponse {\n  text: string;\n  confidence?: number;\n  tokenUsage?: number;\n  metadata?: Record<string, unknown>;\n}\n\ninterface ProviderOptions {\n  timeout?: number;\n  maxTokens?: number;\n}\n\nabstract class ProviderClient {\n  abstract generateResponse(prompt: string, options?: ProviderOptions): Promise<ProviderResponse>;\n  async cleanup?(): Promise<void> {}\n}\n\n// ==================== PROVIDER IMPLEMENTATIONS ====================\n\n/**\n * Claude provider implementation\n */\nclass ClaudeProvider extends ProviderClient {\n  async generateResponse(prompt: string, options?: ProviderOptions): Promise<ProviderResponse> {\n    // Mock implementation - would use actual Claude API\n    await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 200));\n    \n    return {\n      text: `Claude response for: ${prompt.substring(0, 50)}...`,\n      confidence: 0.85 + Math.random() * 0.1,\n      tokenUsage: 150 + Math.floor(Math.random() * 100),\n      metadata: { provider: 'claude', model: 'claude-3' }\n    };\n  }\n}\n\n/**\n * OpenAI provider implementation\n */\nclass OpenAIProvider extends ProviderClient {\n  constructor(private model: string) {\n    super();\n  }\n  \n  async generateResponse(prompt: string, options?: ProviderOptions): Promise<ProviderResponse> {\n    // Mock implementation - would use actual OpenAI API\n    await new Promise(resolve => setTimeout(resolve, 200 + Math.random() * 300));\n    \n    return {\n      text: `OpenAI ${this.model} response for: ${prompt.substring(0, 50)}...`,\n      confidence: 0.75 + Math.random() * 0.15,\n      tokenUsage: 120 + Math.floor(Math.random() * 80),\n      metadata: { provider: 'openai', model: this.model }\n    };\n  }\n}\n\n/**\n * Google Gemini provider implementation\n */\nclass GeminiProvider extends ProviderClient {\n  async generateResponse(prompt: string, options?: ProviderOptions): Promise<ProviderResponse> {\n    // Mock implementation - would use actual Gemini API\n    await new Promise(resolve => setTimeout(resolve, 150 + Math.random() * 250));\n    \n    return {\n      text: `Gemini response for: ${prompt.substring(0, 50)}...`,\n      confidence: 0.8 + Math.random() * 0.1,\n      tokenUsage: 130 + Math.floor(Math.random() * 90),\n      metadata: { provider: 'google', model: 'gemini-pro' }\n    };\n  }\n}"